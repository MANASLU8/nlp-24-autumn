{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1999,
     "status": "ok",
     "timestamp": 1728391542216,
     "user": {
      "displayName": "Vasilisa Lisitsina",
      "userId": "10723223822924824061"
     },
     "user_tz": -180
    },
    "id": "HLphr_XIbkIA",
    "ExecuteTime": {
     "end_time": "2024-10-22T11:01:44.859950600Z",
     "start_time": "2024-10-22T11:01:44.806189Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data from TSV files and exclude the first column.\n",
    "# Assuming the first column is not needed, e.g., it could be an ID or a word that we don't need for vector processing.\n",
    "vec_1 = pd.read_csv(\"corpus/space_vec.tsv\", delimiter='\\t', header=None).iloc[:, 1:]\n",
    "vec_2 = pd.read_csv(\"corpus/elec_vec.tsv\", delimiter='\\t', header=None).iloc[:, 1:]\n",
    "vec_3 = pd.read_csv(\"corpus/med_vec.tsv\", delimiter='\\t', header=None).iloc[:, 1:]\n",
    "\n",
    "# Assign target values to each dataset. These will be used as labels in a classification task.\n",
    "vec_1['target'] = 0  # Directly assign value instead of using np.ones and multiplication\n",
    "vec_2['target'] = 1\n",
    "vec_3['target'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1689,
     "status": "ok",
     "timestamp": 1728391551083,
     "user": {
      "displayName": "Vasilisa Lisitsina",
      "userId": "10723223822924824061"
     },
     "user_tz": -180
    },
    "id": "u78oBv5CcsQe",
    "ExecuteTime": {
     "end_time": "2024-10-22T11:01:51.011933300Z",
     "start_time": "2024-10-22T11:01:50.718715500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split each dataset into training and testing sets with a consistent random state for reproducibility.\n",
    "train_1, test_1 = train_test_split(vec_1, test_size=0.2, random_state=42)\n",
    "train_2, test_2 = train_test_split(vec_2, test_size=0.2, random_state=42)\n",
    "train_3, test_3 = train_test_split(vec_3, test_size=0.2, random_state=42)\n",
    "\n",
    "# Combine the individual training and testing datasets into single datasets.\n",
    "train_set = pd.concat([train_1, train_2, train_3], ignore_index=True)\n",
    "test_set = pd.concat([test_1, test_2, test_3], ignore_index=True)\n",
    "\n",
    "# Separate features (X) and labels (y) for both training and testing sets.\n",
    "X_train, y_train = train_set.drop(columns='target'), train_set['target']\n",
    "X_test, y_test = test_set.drop(columns='target'), test_set['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1728398132160,
     "user": {
      "displayName": "Vasilisa Lisitsina",
      "userId": "10723223822924824061"
     },
     "user_tz": -180
    },
    "id": "El-1jH2Oee35",
    "ExecuteTime": {
     "end_time": "2024-10-22T11:01:58.464377900Z",
     "start_time": "2024-10-22T11:01:58.452281400Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, multilabel_confusion_matrix\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall, F1 score, and accuracy from the true and predicted labels.\n",
    "    \n",
    "    :param y_true: The ground truth (correct) target values.\n",
    "    :param y_pred: The estimated targets as returned by a classifier.\n",
    "    :return: A tuple of (precision, recall, f1_score, accuracy)\n",
    "    \"\"\"\n",
    "    # Compute the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Extract the counts for True Positives (TP), False Positives (FP), False Negatives (FN), and True Negatives (TN)\n",
    "    TP = np.diag(cm)  # Number of correctly classified samples per class\n",
    "    FP = cm.sum(axis=0) - TP  # Number of misclassified samples as each class\n",
    "    FN = cm.sum(axis=1) - TP  # Number of samples that should have been classified as each class but were not\n",
    "    TN = cm.sum() - (FP + FN + TP)  # Number of samples that are neither true nor false positives or negatives\n",
    "\n",
    "    # Calculate precision, recall, F1 score, and accuracy\n",
    "    # Use np.nan_to_num to handle division by zero, which can occur if there are no positive predictions or true positives\n",
    "    precision = np.nan_to_num(TP / (TP + FP))\n",
    "    recall = np.nan_to_num(TP / (TP + FN))\n",
    "    f1_score = np.nan_to_num(2 * (precision * recall) / (precision + recall))\n",
    "    accuracy = np.nan_to_num((TP + TN) / (TP + FP + FN + TN))\n",
    "\n",
    "    # Return the mean of the metrics across all classes\n",
    "    return np.nanmean(precision), np.nanmean(recall), np.nanmean(f1_score), np.nanmean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1080,
     "status": "ok",
     "timestamp": 1728404761609,
     "user": {
      "displayName": "Vasilisa Lisitsina",
      "userId": "10723223822924824061"
     },
     "user_tz": -180
    },
    "id": "SxUCmuGBfP5H",
    "outputId": "0a69c39c-32f3-403c-a582-15c7bd0a160d",
    "ExecuteTime": {
     "end_time": "2024-10-22T11:02:01.875009700Z",
     "start_time": "2024-10-22T11:02:01.593321100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheHs\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import time\n",
    "def train_svm_with_kernels(X_train, X_test, y_train, y_test):\n",
    "    kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    results = []\n",
    "\n",
    "    for kernel in kernels:\n",
    "        model = SVC(kernel=kernel, max_iter=1000)\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        precision, recall, f1, accuracy = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "        results.append({\n",
    "            'kernel': kernel,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'accuracy': accuracy,\n",
    "            'training_time': training_time\n",
    "        })\n",
    "    return results\n",
    "results = train_svm_with_kernels(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1728398117029,
     "user": {
      "displayName": "Vasilisa Lisitsina",
      "userId": "10723223822924824061"
     },
     "user_tz": -180
    },
    "id": "nUq-4t2if324",
    "outputId": "320a7d44-599b-46bd-9e09-10f1e7af0531",
    "ExecuteTime": {
     "end_time": "2024-10-22T11:02:08.011081700Z",
     "start_time": "2024-10-22T11:02:08.007878200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    kernel  precision    recall  f1_score  accuracy  training_time\n0   linear   0.749734  0.752479  0.750483  0.834734       0.018181\n1     poly   0.761765  0.713502  0.710779  0.809524       0.020853\n2      rbf   0.752137  0.748154  0.749859  0.831933       0.020820\n3  sigmoid   0.665038  0.668091  0.664310  0.778711       0.014660",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>kernel</th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1_score</th>\n      <th>accuracy</th>\n      <th>training_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>linear</td>\n      <td>0.749734</td>\n      <td>0.752479</td>\n      <td>0.750483</td>\n      <td>0.834734</td>\n      <td>0.018181</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>poly</td>\n      <td>0.761765</td>\n      <td>0.713502</td>\n      <td>0.710779</td>\n      <td>0.809524</td>\n      <td>0.020853</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>rbf</td>\n      <td>0.752137</td>\n      <td>0.748154</td>\n      <td>0.749859</td>\n      <td>0.831933</td>\n      <td>0.020820</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sigmoid</td>\n      <td>0.665038</td>\n      <td>0.668091</td>\n      <td>0.664310</td>\n      <td>0.778711</td>\n      <td>0.014660</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4635,
     "status": "ok",
     "timestamp": 1728405365289,
     "user": {
      "displayName": "Vasilisa Lisitsina",
      "userId": "10723223822924824061"
     },
     "user_tz": -180
    },
    "id": "62HqlKy3gZvZ",
    "outputId": "cbaadcc2-6ae9-40c1-a541-0d7a4ec5d9d6",
    "ExecuteTime": {
     "end_time": "2024-10-22T12:57:55.284699800Z",
     "start_time": "2024-10-22T12:57:55.008769600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TheHs\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "C:\\Users\\TheHs\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:312: RuntimeWarning: invalid value encountered in log1p\n",
      "  return func(X, **(kw_args if kw_args else {}))\n",
      "C:\\Users\\TheHs\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:312: RuntimeWarning: invalid value encountered in log1p\n",
      "  return func(X, **(kw_args if kw_args else {}))\n",
      "C:\\Users\\TheHs\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(945, 100)\n",
      "(945, 300)\n",
      "Results:\n",
      "    kernel  precision    recall  f1_score  accuracy  training_time\n",
      "0   linear   0.749734  0.752479  0.750483  0.834734       0.018181\n",
      "1     poly   0.761765  0.713502  0.710779  0.809524       0.020853\n",
      "2      rbf   0.752137  0.748154  0.749859  0.831933       0.020820\n",
      "3  sigmoid   0.665038  0.668091  0.664310  0.778711       0.014660\n",
      "Results with PCA:\n",
      "    kernel  precision    recall  f1_score  accuracy  training_time\n",
      "0   linear   0.780014  0.781804  0.780635  0.854342       0.012508\n",
      "1     poly   0.723840  0.569937  0.556147  0.714286       0.019517\n",
      "2      rbf   0.756288  0.752373  0.753992  0.834734       0.019972\n",
      "3  sigmoid   0.667685  0.672468  0.668416  0.781513       0.016557\n",
      "Results with new features:\n",
      "    kernel  precision    recall  f1_score  accuracy  training_time\n",
      "0   linear   0.748463  0.752321  0.747618  0.834734       0.020706\n",
      "1     poly   0.768212  0.717722  0.716445  0.812325       0.028299\n",
      "2      rbf   0.753529  0.748207  0.750335  0.831933       0.029557\n",
      "3  sigmoid   0.670241  0.672521  0.666839  0.781513       0.023526\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import time\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import pandas as pd\n",
    "\n",
    "def reduce_dimensions_pca(X_train, X_test, n_components):\n",
    "    # Apply PCA to reduce dimensions\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    return X_train_pca, X_test_pca\n",
    "\n",
    "def add_features(X_train, X_test):\n",
    "    # Add log and sin transformed features\n",
    "    transformer_log = FunctionTransformer(np.log1p, validate=True)\n",
    "    transformer_sin = FunctionTransformer(np.sin, validate=True)\n",
    "\n",
    "    X_train_log = transformer_log.transform(X_train)\n",
    "    X_test_log = transformer_log.transform(X_test)\n",
    "    X_train_sin = transformer_sin.transform(X_train)\n",
    "    X_test_sin = transformer_sin.transform(X_test)\n",
    "\n",
    "    # Combine original and new features\n",
    "    X_train_new = np.hstack([X_train, X_train_log, X_train_sin])\n",
    "    X_test_new = np.hstack([X_test, X_test_log, X_test_sin])\n",
    "\n",
    "    return X_train_new, X_test_new\n",
    "\n",
    "def preprocess_data(X_train, X_test):\n",
    "    # Impute missing values with mean\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    return X_train_imputed, X_test_imputed\n",
    "\n",
    "def train_svm_with_kernels(X_train, X_test, y_train, y_test):\n",
    "    kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    results = []\n",
    "\n",
    "    for kernel in kernels:\n",
    "        model = SVC(kernel=kernel, max_iter=1000)\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train, y_train)\n",
    "        training_time = time.time() - start_time\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        results.append({\n",
    "            'kernel': kernel,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1,\n",
    "            'accuracy': accuracy,\n",
    "            'training_time': training_time\n",
    "        })\n",
    "    return results\n",
    "\n",
    "def run_experiment(X_train, X_test, y_train, y_test, pca_components):\n",
    "    # Run experiment with PCA\n",
    "    X_train_pca, X_test_pca = reduce_dimensions_pca(X_train, X_test, pca_components)\n",
    "    pca_results = train_svm_with_kernels(X_train_pca, X_test_pca, y_train, y_test)\n",
    "\n",
    "    # Run experiment with additional features\n",
    "    X_train_new, X_test_new = add_features(X_train, X_test)\n",
    "    X_train_new, X_test_new = preprocess_data(X_train_new, X_test_new)\n",
    "    feature_results = train_svm_with_kernels(X_train_new, X_test_new, y_train, y_test)\n",
    "\n",
    "    return pca_results, feature_results\n",
    "\n",
    "# Experiment parameters\n",
    "pca_components = 90\n",
    "\n",
    "# Run the experiment\n",
    "pca_results, feature_results = run_experiment(X_train, X_test, y_train, y_test, pca_components)\n",
    "\n",
    "# Print results\n",
    "print(\"Results with PCA:\")\n",
    "print(pd.DataFrame(pca_results))\n",
    "\n",
    "print(\"Results with new features:\")\n",
    "print(pd.DataFrame(feature_results))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO+IlqZO+i4spvcoAarK7Xk",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
