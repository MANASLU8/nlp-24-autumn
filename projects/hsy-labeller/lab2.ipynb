{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2xcnKRFcTpF1",
    "outputId": "702139f2-4794-48fd-fc90-18bf2f22ac95"
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "\n",
    "sentences = list()\n",
    "sentence = list()\n",
    "with open('annotations_hsy2.tsv') as file:\n",
    "  for line in file:\n",
    "      if line != \"\\n\":\n",
    "        sentence.append(line.split('\\t')[1])\n",
    "      if line == \"\\n\" and sentence:\n",
    "        sentences.append(sentence)\n",
    "        sentence = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "5R0p0d0kWXoz",
    "ExecuteTime": {
     "end_time": "2024-10-15T09:09:23.543454700Z",
     "start_time": "2024-10-15T09:09:21.438868200Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "clear_data = []\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "    cleaned = []\n",
    "    for lemma in sentence:\n",
    "        cleaned_token = re.sub(r\"(?<!\\w)\\.(?!\\w)|[^\\w\\s@._-]+\", \"\", lemma.lower())\n",
    "        if cleaned_token and cleaned_token not in stop_words:\n",
    "            cleaned.append(cleaned_token)\n",
    "    return cleaned\n",
    "\n",
    "for sentence in sentences:\n",
    "    clear_data.append(clean_sentence(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "a31Sv8S4Wivp",
    "ExecuteTime": {
     "end_time": "2024-10-15T09:10:27.075758600Z",
     "start_time": "2024-10-15T09:10:25.314427200Z"
    }
   },
   "outputs": [],
   "source": [
    "trigrams = list()\n",
    "for sentence in clear_data:\n",
    "    for i in range(len(sentence) - 2):\n",
    "        trigrams.append(sentence[i:i+3])\n",
    "        \n",
    "trigram_frequency = dict()\n",
    "for trigram in trigrams:\n",
    "    if tuple(trigram) not in trigram_frequency:\n",
    "        # If not existed, create it\n",
    "        trigram_frequency[tuple(trigram)] = 1\n",
    "    else:\n",
    "        # If existed, add it.\n",
    "        trigram_frequency[tuple(trigram)] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "HbEGbSDWYwQk",
    "ExecuteTime": {
     "end_time": "2024-10-15T09:10:31.498622300Z",
     "start_time": "2024-10-15T09:10:31.496108700Z"
    }
   },
   "outputs": [],
   "source": [
    "def mi_score(trigram_frequencies, word_counts, total_words):\n",
    "    # Initialize a dictionary to store the MI scores for each trigram\n",
    "    miscores = {}\n",
    "    \n",
    "    # Iterate over each trigram and its frequency in the trigram_frequencies dictionary\n",
    "    for trigram, count in trigram_frequencies.items():\n",
    "        # Calculate the denominator: product of the counts of individual words in the trigram\n",
    "        denominator = word_counts[trigram[0]] * word_counts[trigram[1]] * word_counts[trigram[2]]\n",
    "        \n",
    "        # Calculate the mutual information (MI) using the provided formula\n",
    "        mi = math.log2((total_words ** 2) * count / denominator)\n",
    "        \n",
    "        # Store the calculated MI score for the current trigram\n",
    "        miscores[trigram] = mi\n",
    "    \n",
    "    # Return the dictionary containing the MI scores for all trigrams\n",
    "    return miscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Hj417jaPYxHK",
    "ExecuteTime": {
     "end_time": "2024-10-15T09:10:34.329633500Z",
     "start_time": "2024-10-15T09:10:33.805545700Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "words_count = Counter()\n",
    "\n",
    "for sentence in clear_data:\n",
    "    words_count.update(sentence)\n",
    "\n",
    "total_words = sum(words_count.values())\n",
    "\n",
    "mi_score = mi_score(trigram_frequency, words_count, total_words)\n",
    "\n",
    "sorted(mi_score.items(), key=lambda x: x[1], reverse=True)[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfwXk7jFZxED",
    "outputId": "23bd3177-38db-45ec-db01-90caae255ba1"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import TrigramAssocMeasures, TrigramCollocationFinder\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "flat_text = [word for sentence in clear_data for word in sentence]\n",
    "\n",
    "finder_thr = TrigramCollocationFinder.from_words(flat_text)\n",
    "\n",
    "trigram_measures = TrigramAssocMeasures()\n",
    "top_30_trigrams = finder_thr.nbest(trigram_measures.pmi, 30)\n",
    "\n",
    "print(top_30_trigrams)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
