{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism\n",
      "comp.graphics\n",
      "alt.atheism\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def get_file_class_map(root_dir):\n",
    "    file_class_map = {}\n",
    "\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        class_name = os.path.basename(root)\n",
    "\n",
    "        if class_name == os.path.basename(root_dir):\n",
    "            continue\n",
    "\n",
    "        for file_name in files:\n",
    "            key = file_name.split('.')[0]\n",
    "            file_class_map[key] = class_name\n",
    "\n",
    "    return file_class_map\n",
    "\n",
    "test_directory = '../../dataset/20news-bydate-test'\n",
    "file_class_test_map = get_file_class_map(test_directory)\n",
    "\n",
    "train_directory = '../../dataset/20news-bydate-train'\n",
    "file_class_train_map = get_file_class_map(train_directory)\n",
    "\n",
    "file_class_map = file_class_test_map | file_class_train_map\n",
    "\n",
    "print(file_class_map['53068'])\n",
    "print(file_class_map['38761'])\n",
    "print(file_class_map['49960'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(file_path):\n",
    "    embeddings = []\n",
    "    doc_ids = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            data = line.strip().split('\\t')\n",
    "            doc_id = data[0]\n",
    "            embedding = list(map(float, data[1:]))\n",
    "            doc_ids.append(doc_id)\n",
    "            embeddings.append(embedding)\n",
    "    return np.array(embeddings), doc_ids\n",
    "\n",
    "def get_labels(doc_ids, file_class_map):\n",
    "    labels = [file_class_map[doc_id] for doc_id in doc_ids]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "train_embedding_file_path = '../../nechkasova-vectorization/assets/annotated-corpus/train.tsv'\n",
    "test_embedding_file_path = '../../nechkasova-vectorization/assets/annotated-corpus/test.tsv'\n",
    "\n",
    "X_train, doc_ids = load_embeddings(train_embedding_file_path)\n",
    "y_train = get_labels(doc_ids, file_class_map)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "X_test, doc_ids = load_embeddings(test_embedding_file_path)\n",
    "y_test = get_labels(doc_ids, file_class_map)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train, X_test, y_train_encoded, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    labels = np.unique(y_true)\n",
    "    precision_per_class = []\n",
    "    recall_per_class = []\n",
    "    f1_score_per_class = []\n",
    "    \n",
    "    total_samples = len(y_true)\n",
    "    \n",
    "    for label in labels:\n",
    "        tp = sum((y_true == label) & (y_pred == label))\n",
    "        fp = sum((y_true != label) & (y_pred == label))\n",
    "        fn = sum((y_true == label) & (y_pred != label))\n",
    "        tn = sum((y_true != label) & (y_pred != label))\n",
    "        \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        precision_per_class.append(precision)\n",
    "        recall_per_class.append(recall)\n",
    "        f1_score_per_class.append(f1_score)\n",
    "    \n",
    "    accuracy = np.sum(y_true == y_pred) / total_samples\n",
    "    \n",
    "    return {\n",
    "        'precision': np.mean(precision_per_class),\n",
    "        'recall': np.mean(recall_per_class),\n",
    "        'f1-score': np.mean(f1_score_per_class),\n",
    "        'accuracy': accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "kernel_params = {\n",
    "    'linear': {'C': [0.1, 1, 10]},\n",
    "    'poly': {'C': [0.1, 1], 'degree': [2, 3], 'coef0': [0.1, 1]},\n",
    "    'rbf': {'C': [0.1, 1], 'gamma': ['scale', 0.1]},\n",
    "    'sigmoid': {'C': [0.1, 1], 'gamma': ['scale', 0.1], 'coef0': [0, 0.5]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_svm(X_train, y_train, X_test, y_test, kernels, kernel_params):\n",
    "    results = {}\n",
    "\n",
    "    for kernel in kernels:\n",
    "        param_values = kernel_params[kernel]\n",
    "        \n",
    "        for C in param_values.get('C', [1]):\n",
    "            for degree in param_values.get('degree', [3]):\n",
    "                for gamma in param_values.get('gamma', ['scale']):\n",
    "                    for coef0 in param_values.get('coef0', [0]):\n",
    "                        model_params = {'kernel': kernel, 'C': C}\n",
    "                        if kernel == 'poly':\n",
    "                            model_params['degree'] = degree\n",
    "                            model_params['coef0'] = coef0\n",
    "                        elif kernel in ['rbf', 'sigmoid']:\n",
    "                            model_params['gamma'] = gamma\n",
    "                            model_params['coef0'] = coef0\n",
    "\n",
    "                        model = SVC(**model_params, random_state=42)\n",
    "                        start_time = time.time()\n",
    "                        model.fit(X_train, y_train)\n",
    "                        train_time = time.time() - start_time\n",
    "\n",
    "                        y_pred = model.predict(X_test)\n",
    "\n",
    "                        metrics = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "                        results[(kernel, C, degree, gamma, coef0)] = {\n",
    "                            'metrics': metrics,\n",
    "                            'training_time': train_time\n",
    "                        }\n",
    "\n",
    "                        print(f\"Kernel: {kernel}, C: {C}, Degree: {degree}, Gamma: {gamma}, Coef0: {coef0}\")\n",
    "                        print(f\"Accuracy: {metrics['accuracy']:.4f}, Precision: {metrics['precision']:.4f}, Recall: {metrics['recall']:.4f}, F1-Score: {metrics['f1-score']:.4f}\")\n",
    "                        print(f\"Training Time: {train_time:.4f} seconds\\n\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM (линейное ядро)\n",
    "results = experiment_svm(X_train, y_train_encoded, X_test, y_test_encoded, kernels, kernel_params)\n",
    "\n",
    "print(\"SVM (линейное ядро) - метрики\")\n",
    "for params, metrics in results.items():\n",
    "    print(f\"Параметры: {params}, Метрики: {metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_options = [(50,), (100,), (100, 50), (100, 100, 50)]\n",
    "max_iter_options = [100, 300, 500, 1000]\n",
    "learning_rate_options = [0.001, 0.01]\n",
    "activation_options = ['relu', 'tanh', 'logistic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_mlp(X_train, y_train, X_test, y_test):\n",
    "    results = {}\n",
    "    \n",
    "    for hidden_layers in hidden_layer_options:\n",
    "        for max_iter in max_iter_options:\n",
    "            for learning_rate in learning_rate_options:\n",
    "                for activation in activation_options:\n",
    "                    model = MLPClassifier(\n",
    "                        hidden_layer_sizes=hidden_layers,\n",
    "                        max_iter=max_iter,\n",
    "                        learning_rate_init=learning_rate,\n",
    "                        activation=activation,\n",
    "                        random_state=42\n",
    "                    )\n",
    "\n",
    "                    start_time = time.time()\n",
    "                    model.fit(X_train, y_train)\n",
    "                    training_time = time.time() - start_time\n",
    "                    \n",
    "                    y_pred = model.predict(X_test)\n",
    "                    metrics = calculate_metrics(y_test, y_pred)\n",
    "\n",
    "                    params = (hidden_layers, max_iter, learning_rate, activation)\n",
    "                    results[params] = {\n",
    "                        'metrics': metrics,\n",
    "                        'training_time': training_time\n",
    "                    }\n",
    "\n",
    "                    print(f\"Params: {params}\")\n",
    "                    print(f\"Metrics: {metrics}\")\n",
    "                    print(f\"Training Time: {training_time:.4f} seconds\\n\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "results = experiment_mlp(X_train, y_train_encoded, X_test, y_test_encoded)\n",
    "\n",
    "print(\"MLP - метрики:\")\n",
    "for params, result in results.items():\n",
    "    print(f\"Params: {params}, Metrics: {result['metrics']}, Training Time: {result['training_time']:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_log1p(embeddings, shift=True):\n",
    "    if shift:\n",
    "        min_value = embeddings.min()\n",
    "        if min_value < -1:\n",
    "            embeddings_shifted = embeddings + abs(min_value) + 1\n",
    "        else:\n",
    "            embeddings_shifted = embeddings\n",
    "        return np.log1p(embeddings_shifted)\n",
    "    else:\n",
    "        return np.log1p(np.abs(embeddings))\n",
    "\n",
    "transformations = [\n",
    "    safe_log1p,\n",
    "    np.sin,\n",
    "    np.cos,\n",
    "    np.square\n",
    "]\n",
    "\n",
    "def extend_embeddings(embeddings, functions):\n",
    "    extended_embeddings = embeddings.copy()\n",
    "    for func in functions:\n",
    "        transformed = func(embeddings)\n",
    "        extended_embeddings = np.concatenate((extended_embeddings, transformed), axis=1)\n",
    "    return extended_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_extended = extend_embeddings(X_train, transformations)\n",
    "X_test_extended = extend_embeddings(X_test, transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_mlp_extended(X_train, y_train, X_test, y_test):\n",
    "    model = MLPClassifier(hidden_layer_sizes=(100, 100, 50), max_iter=300, learning_rate_init=0.01, activation='logistic')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = calculate_metrics(y_test, y_pred)\n",
    "    \n",
    "    return metrics, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_mlp, training_time_mlp = experiment_mlp_extended(X_train_extended, y_train_encoded, X_test_extended, y_test_encoded)\n",
    "print(metrics_mlp)\n",
    "print(\"Training Time:\", training_time_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_extended = extend_embeddings(X_train, [np.sin])\n",
    "X_test_extended = extend_embeddings(X_test, [np.sin])\n",
    "\n",
    "metrics_mlp, training_time_mlp = experiment_mlp_extended(X_train_extended, y_train_encoded, X_test_extended, y_test_encoded)\n",
    "print(metrics_mlp)\n",
    "print(\"Training Time:\", training_time_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_extended = extend_embeddings(X_train, [np.square])\n",
    "X_test_extended = extend_embeddings(X_test, [np.square])\n",
    "\n",
    "metrics_mlp, training_time_mlp = experiment_mlp_extended(X_train_extended, y_train_encoded, X_test_extended, y_test_encoded)\n",
    "print(metrics_mlp)\n",
    "print(\"Training Time:\", training_time_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_extended = extend_embeddings(X_train, [safe_log1p])\n",
    "X_test_extended = extend_embeddings(X_test, [safe_log1p])\n",
    "\n",
    "metrics_mlp, training_time_mlp = experiment_mlp_extended(X_train_extended, y_train_encoded, X_test_extended, y_test_encoded)\n",
    "print(metrics_mlp)\n",
    "print(\"Training Time:\", training_time_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_extended = extend_embeddings(X_train, [np.sin, np.square])\n",
    "X_test_extended = extend_embeddings(X_test, [np.sin, np.square])\n",
    "\n",
    "metrics_mlp, training_time_mlp = experiment_mlp_extended(X_train_extended, y_train_encoded, X_test_extended, y_test_encoded)\n",
    "print(metrics_mlp)\n",
    "print(\"Training Time:\", training_time_mlp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
