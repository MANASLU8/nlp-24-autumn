{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTT-Dx8R-LpL",
    "outputId": "22fcdf29-468b-420d-85cb-d83ed621f0b5"
   },
   "outputs": [],
   "source": [
    "# !pip install evaluate==0.4.3\n",
    "# !pip install llama-cpp-python==0.1.9\n",
    "# !pip install pinecone-client==5.0.1\n",
    "# !pip install langchain_community==0.2.16\n",
    "# !pip install langchain-chroma==0.1.4\n",
    "# !pip install chromadb==0.5.11\n",
    "# !pip install sentence-transformers==3.1.1\n",
    "# !pip install ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "tcb0TE2y9o0S"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PDFMinerLoader, TextLoader, CSVLoader, UnstructuredWordDocumentLoader, UnstructuredHTMLLoader\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from langchain_chroma.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from chromadb.config import Settings\n",
    "from chromadb import Client\n",
    "from llama_cpp import Llama\n",
    "from evaluate import load\n",
    "from typing import Any\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "qlQsKNbjCsf5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import pinecone\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "w2p_plKvbacZ"
   },
   "outputs": [],
   "source": [
    "path_to_index = '/content/VDB'\n",
    "path_to_documents = 'nlp-24-autumn/projects/dataset/20news-bydate-train/comp.graphics' #49960.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "XyaoDfoC9bmT"
   },
   "outputs": [],
   "source": [
    "# Словарь, сопоставляющий расширения файлов с соответствующими загрузчиками данных и их параметрами\n",
    "LOADER_MAPPING = {\n",
    "    \".csv\": (CSVLoader, {}),\n",
    "    \".doc\": (UnstructuredWordDocumentLoader, {}),\n",
    "    \".docx\": (UnstructuredWordDocumentLoader, {}),\n",
    "    \".html\": (UnstructuredHTMLLoader, {}),\n",
    "    \".pdf\": (PDFMinerLoader, {}),\n",
    "    \".txt\": (TextLoader, {\"encoding\": \"ISO-8859-1\"}),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "_kofnU15EBEf"
   },
   "outputs": [],
   "source": [
    "# Параметры конфигурации для векторного поиска и разделения текста\n",
    "INDEX_NAME = \"VDB\"  # Название индекса для хранения векторных представлений\n",
    "COLLECTION_NAME = \"document_collection\"\n",
    "EMBEDDINGS = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"  # Название модели эмбеддингов, используемой для векторизации текстов\n",
    "SIZE = 250  # Размер фрагмента текста для разделения документов\n",
    "OVERLAP = 50  # Перекрытие между фрагментами текста для обеспечения контекста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKhOsNCaC-ds"
   },
   "source": [
    "## Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Wuqy7ZApCS1-"
   },
   "outputs": [],
   "source": [
    "# Класс для загрузки документов из различных источников, поддерживающий работу с разными форматами файлов\n",
    "class Loader:\n",
    "    def load_single_document(self, file_path: str):\n",
    "        # Метод для загрузки одного документа на основе пути к файлу\n",
    "        ext = Path(file_path).suffix.lower()\n",
    "        if ext in LOADER_MAPPING:\n",
    "            loader_class, loader_args = LOADER_MAPPING[ext]\n",
    "            loader_args['file_path'] = file_path;\n",
    "            loader = loader_class(**loader_args)\n",
    "            document = loader.load()\n",
    "            return document\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file extension: {ext}\")\n",
    "\n",
    "    def load_documents(self, source_dir: str):\n",
    "        # Метод для загрузки всех документов из указанной директории\n",
    "        documents = []\n",
    "        if os.path.isfile(source_dir):\n",
    "          documents.extend(self.load_single_document(file_path))\n",
    "        else:\n",
    "          for root, _, files in os.walk(source_dir):\n",
    "              for file_name in files:\n",
    "                  file_path = os.path.join(root, file_name)\n",
    "                  try:\n",
    "                      document = self.load_single_document(file_path)\n",
    "                      documents.extend(document)\n",
    "                  except ValueError as e:\n",
    "                      print(e)\n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4l1GR3fRVgR",
    "outputId": "b8c7cb80-ffc1-43df-e265-12e52add1f7e"
   },
   "outputs": [],
   "source": [
    "loader = Loader()\n",
    "\n",
    "example_document = loader.load_documents(path_to_documents)\n",
    "\n",
    "print(example_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDGCH3WV_A8p"
   },
   "source": [
    "## Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "CvN9kIBmCyDJ"
   },
   "outputs": [],
   "source": [
    "# Класс для разделения документов на фрагменты определённого размера с заданным перекрытием\n",
    "class Splitter:\n",
    "    def __init__(self, chunk_size, chunk_overlap):\n",
    "        # Инициализация параметров разделения: размер фрагмента и величина перекрытия\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "\n",
    "    def split_documents(self, documents):\n",
    "        fragments = []\n",
    "        for document in documents:\n",
    "            text = document.page_content\n",
    "            doc_meta = document.metadata\n",
    "            start = 0\n",
    "\n",
    "            while start < len(text):\n",
    "                end = min(start + self.chunk_size, len(text))\n",
    "                fragment_text = text[start:end]\n",
    "\n",
    "                fragment = {\n",
    "                    \"text\": fragment_text,\n",
    "                    \"metadata\": doc_meta\n",
    "                }\n",
    "\n",
    "                fragments.append(fragment)\n",
    "                start += self.chunk_size - self.chunk_overlap\n",
    "\n",
    "        return fragments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mLvATkgCiK_5",
    "outputId": "d28fd2bf-4001-45e5-bd61-b05e828c5349"
   },
   "outputs": [],
   "source": [
    "splitter = Splitter(SIZE, OVERLAP)\n",
    "\n",
    "example_fragments = splitter.split_documents(example_document)\n",
    "\n",
    "example_fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohzsSpJX9u3n"
   },
   "source": [
    "##Vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "soiFkrEC_kPH"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Базовый класс для создания эмбеддингов, обеспечивающий интерфейс для получения модели эмбеддингов\n",
    "class Embedder:\n",
    "    def __init__(self, model_name: str):\n",
    "        # Инициализация эмбеддера\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def get_embedder(self):\n",
    "        # Метод для получения модели эмбеддингов, которая будет использоваться для векторизации текстов\n",
    "        return self.model\n",
    "\n",
    "    def encode(self, texts: list[dict]):\n",
    "        return self.model.encode(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "grQtAn0VDPqy"
   },
   "outputs": [],
   "source": [
    "class HuggingFaceEmbedder(Embedder):\n",
    "    def __init__(self):\n",
    "        super().__init__(EMBEDDINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "taLZSFKbkbTh",
    "outputId": "2cb9c8d7-c85a-41ac-bed3-79f8685100aa"
   },
   "outputs": [],
   "source": [
    "embedder = HuggingFaceEmbedder()\n",
    "\n",
    "example_embedded_fragments = embedder.encode(example_fragments)\n",
    "\n",
    "example_embedded_fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJU4AdHrdXu8"
   },
   "source": [
    "### Класс Collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "hqk-o5RA-97P"
   },
   "outputs": [],
   "source": [
    "# Базовый класс для работы с коллекцией документов, поддерживающий добавление, поиск и очистку данных\n",
    "class Collector:\n",
    "    def __init__(self, splitter: Splitter, embedder: Embedder):\n",
    "        self.splitter = splitter\n",
    "        self.embedder = embedder\n",
    "        self.loader = Loader()\n",
    "\n",
    "    def add(self, texts: list[str], metadatas: list[dict]):\n",
    "        # Метод для добавления текстов и связанных с ними метаданных в коллекцию\n",
    "        embeddings = self.embedder.encode(texts)\n",
    "        return [{\"embedding\": embedding, \"metadata\": metadata} for embedding, metadata in zip(embeddings, metadatas)]\n",
    "\n",
    "    def add_from_directory(self, dir_path: str):\n",
    "        # Метод для добавления документов в коллекцию из указанной директории\n",
    "        documents = self.loader.load_documents(dir_path)\n",
    "        fragments = self.splitter.split_documents(documents)\n",
    "\n",
    "        texts = [fragment[\"text\"] for fragment in fragments]\n",
    "        metadatas = [fragment[\"metadata\"] for fragment in fragments]\n",
    "        self.add(texts, metadatas)\n",
    "\n",
    "    def _cosine_similarity(self, vec1, vec2):\n",
    "        dot_product = sum(a * b for a, b in zip(vec1, vec2))\n",
    "        norm1 = sum(a ** 2 for a in vec1) ** 0.5\n",
    "        norm2 = sum(b ** 2 for b in vec2) ** 0.5\n",
    "        return dot_product / (norm1 * norm2)\n",
    "\n",
    "    def query_documents(self, embedding, top_k):\n",
    "        pass\n",
    "\n",
    "    def get(self, search_strings: list[str], n_results: int) -> list[Document]:\n",
    "        # Метод для поиска документов по строкам запроса с ограничением на количество результатов\n",
    "        search_embeddings = self.embedder.encode(search_strings)\n",
    "        results = []\n",
    "        for search_embedding in search_embeddings:\n",
    "            result_docs = self.query_documents(search_embedding, top_k=n_results)\n",
    "            results.extend(result_docs)\n",
    "        return results\n",
    "\n",
    "    def get_documents(self, search_string: str, n_results: int, score_threshold: float) -> list[Document]:\n",
    "        # Метод для поиска документов с учётом порога релевантности и количества возвращаемых результатов\n",
    "        search_embedding = self.embedder.encode([search_string])[0]\n",
    "        result_docs = self.query_documents(search_embedding, top_k=n_results)\n",
    "        return [doc for doc in result_docs if doc.score >= score_threshold]\n",
    "\n",
    "\n",
    "class ChromaCollector(Collector):\n",
    "    def __init__(self, splitter: Splitter, embedder: HuggingFaceEmbedder):\n",
    "        super().__init__(splitter, embedder)\n",
    "        self.client = Client()\n",
    "        self.collection = self.client.get_or_create_collection(COLLECTION_NAME)\n",
    "        self.doc_id_counter = 0\n",
    "\n",
    "    def add(self, texts: list[str], metadatas: list[dict]):\n",
    "        # Добавляем документы с их эмбеддингами и метаданными в коллекцию\n",
    "        added_documents = super().add(texts, metadatas)\n",
    "        embeddings = np.array([doc[\"embedding\"] for doc in added_documents]).astype(\"float32\")\n",
    "\n",
    "        ids = [f\"id_{self.doc_id_counter + i}\" for i in range(len(added_documents))]\n",
    "        self.doc_id_counter += len(added_documents)\n",
    "\n",
    "        self.collection.add(\n",
    "            documents=texts,\n",
    "            embeddings=embeddings.tolist(),\n",
    "            metadatas=[doc[\"metadata\"] for doc in added_documents],\n",
    "            ids=ids\n",
    "        )\n",
    "\n",
    "    def query_documents(self, query_embedding, top_k: int):\n",
    "        results = self.collection.query(\n",
    "            query_embeddings=[query_embedding.tolist()],\n",
    "            n_results=top_k\n",
    "        )\n",
    "\n",
    "        ids = results['ids'][0]\n",
    "        distances = results['distances'][0]\n",
    "        metadatas = results['metadatas'][0]\n",
    "        documents = results['documents'][0]\n",
    "\n",
    "        results_list = []\n",
    "        for i in range(len(ids)):\n",
    "            results_list.append({\n",
    "                \"id\": ids[i],\n",
    "                \"distance\": distances[i],\n",
    "                \"metadata\": metadatas[i],\n",
    "                \"document\": documents[i]\n",
    "            })\n",
    "\n",
    "        return results_list\n",
    "\n",
    "\n",
    "    def clear(self):\n",
    "        self.client.delete_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6XXhGdIuDmUU"
   },
   "source": [
    "###Implementation vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "h8xU0gGbERSk"
   },
   "outputs": [],
   "source": [
    "# path_to_index = '/content/VDB' #@param {type:\"string\"}\n",
    "# path_to_documents = '/content/tmp' #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "v631_WnyDMUw"
   },
   "outputs": [],
   "source": [
    "#Нужно написать реализацию векторной базы данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EP4n4OAZ_VuG"
   },
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "E6s-niuuIlqB"
   },
   "outputs": [],
   "source": [
    "query = 'How can I clean a suede jacket?' #@param {type:\"string\"}\n",
    "n_results = 5 #@param {type:\"integer\"}\n",
    "score_threshold = 0.5 # @param {type:\"slider\", min:0, max:1, step:0.1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z7YvW8XXaL-H",
    "outputId": "e0786226-6da4-456f-fa13-03382ba4a2af"
   },
   "outputs": [],
   "source": [
    "#Нужно реализовать эксперимент по поиску в векторном индексе\n",
    "example_splitter = Splitter(SIZE, OVERLAP)\n",
    "example_embedder = HuggingFaceEmbedder()\n",
    "exampple_collector = ChromaCollector(splitter, embedder)\n",
    "\n",
    "exampple_collector.clear()\n",
    "exampple_collector = ChromaCollector(example_splitter, example_embedder)\n",
    "\n",
    "exaple_documents = [\n",
    "        \"The sun is an average star.\",\n",
    "        \"The moon orbits the Earth.\",\n",
    "        \"I enjoy cooking and baking.\",\n",
    "        \"The galaxy is vast and full of stars.\",\n",
    "        \"Artificial intelligence is transforming industries.\"\n",
    "    ]\n",
    "\n",
    "example_metadatas = [\n",
    "    {'file_path': 'dir_1'},\n",
    "    {'file_path': 'dir_2'},\n",
    "    {'file_path': 'dir_3'},\n",
    "    {'file_path': 'dir_4'},\n",
    "    {'file_path': 'dir_5'},\n",
    "    ]\n",
    "\n",
    "\n",
    "exampple_collector.add(exaple_documents, example_metadatas)\n",
    "exampple_collector.collection.peek()\n",
    "\n",
    "example_query = \"What is sun?\"\n",
    "example_query_embedding = embedder.encode([example_query])[0]\n",
    "exampple_collector.query_documents(example_query_embedding, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "EYWiLay4cqBR"
   },
   "outputs": [],
   "source": [
    "splitter = Splitter(SIZE, OVERLAP)\n",
    "embedder = HuggingFaceEmbedder()\n",
    "collector = ChromaCollector(splitter, embedder)\n",
    "\n",
    "collector.clear()\n",
    "collector = ChromaCollector(splitter, embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "iBsTDaKFgS6v"
   },
   "outputs": [],
   "source": [
    "path_to_documents = '../../dataset/20news-bydate-train/comp.graphics'\n",
    "\n",
    "collector.add_from_directory(path_to_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YARkyirkv3wO",
    "outputId": "a4b56270-16f4-4a56-d726-d18d7e07d358"
   },
   "outputs": [],
   "source": [
    "collector.collection.peek(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSiiVKiad0Rn",
    "outputId": "198570a1-34c9-4472-96c2-d7791a997f46"
   },
   "outputs": [],
   "source": [
    "search_queries = [\"What tools does include ImageMagick?\"]\n",
    "\n",
    "for query in search_queries:\n",
    "    print(f\"\\nSearch query: {query}\")\n",
    "    results = collector.get([query], n_results=n_results)\n",
    "\n",
    "    for i, doc in enumerate(results):\n",
    "        print(f\"Result {i + 1}: {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6lzqXLZ_YtU"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "WHZ6IMLIQq2-"
   },
   "outputs": [],
   "source": [
    "# Класс для оценки работы коллектора, предоставляющий функционал для поиска, оценки и расчета статистики по результатам\n",
    "class CollectorEvaluator:\n",
    "    def __init__(self, collector: Collector, n_top=5):\n",
    "        # Инициализация коллектора и параметра n_top для ограничения числа возвращаемых результатов\n",
    "        self.collector = collector\n",
    "        self.n_top = n_top\n",
    "\n",
    "    def explore_collector(self, text: str):\n",
    "        # Метод для поиска документов в коллекторе на основе текста запроса\n",
    "        collector_results = self.collector.get([text], n_results=self.n_top)\n",
    "        return collector_results\n",
    "\n",
    "    def eval(self, query: str, answer: str):\n",
    "        # Метод для оценки корректности найденных документов на основе запроса и правильного ответа\n",
    "        collector_results = self.explore_collector(query)\n",
    "\n",
    "        print(f\"\\nSearch query: {query},\\nanswer: {answer}\")\n",
    "\n",
    "        for i, doc in enumerate(collector_results, start=1):\n",
    "            print(f\"Result {i}: {doc}\")\n",
    "\n",
    "        for i, doc in enumerate(collector_results, start=1):\n",
    "            if answer in doc[\"document\"]:\n",
    "                return i\n",
    "        return None\n",
    "\n",
    "    def calculate_statistics(self, data: list[int]):\n",
    "        # Метод для расчета статистических показателей (например, минимальное, максимальное, среднее значение)\n",
    "\n",
    "        filtered_data = [serial_number for serial_number in data if serial_number is not None]\n",
    "        not_found_queries = len([serial_number for serial_number in data if serial_number is None])\n",
    "\n",
    "        if not filtered_data:\n",
    "            return {\"min\": None, \"max\": None, \"mean\": None, \"not found\": None}\n",
    "\n",
    "        min_serial_number = min(filtered_data)\n",
    "        max_serial_number = max(filtered_data)\n",
    "        mean_serial_number = sum(filtered_data) / len(filtered_data)\n",
    "        return {\"min\": min_serial_number, \"max\": max_serial_number, \"mean\": mean_serial_number, \"not_found\": not_found_queries / len(data)}\n",
    "\n",
    "    def explore_and_calculate(self, data: list[tuple[str, str]]):\n",
    "        # Метод для проведения поиска по данным и расчета статистики на основе результатов\n",
    "        collector_results = []\n",
    "        for query, answer in data:\n",
    "            serial_number = self.eval(query, answer)\n",
    "            collector_results.append(serial_number)\n",
    "\n",
    "        stats = self.calculate_statistics(collector_results)\n",
    "        return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "VFNalqWBkF-m"
   },
   "outputs": [],
   "source": [
    "path_to_dataset = '/content/QA.csv' #@param {type:\"string\"}\n",
    "n_lines = 100 #@param {type:\"integer\"}\n",
    "n_top = 10 #@param {type:\"integer\"}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWlAHfzYjw4X",
    "outputId": "f737d7fe-bcd1-4335-f4a2-dc9a28aa7051"
   },
   "outputs": [],
   "source": [
    "#Нужно написать эксперимент для оценки полученной коллекции\n",
    "example_collector = ChromaCollector(example_splitter, example_embedder)\n",
    "example_evaluator = CollectorEvaluator(example_collector, n_top=n_top)\n",
    "\n",
    "example_data = [\n",
    "    (\"What is the sun?\", \"The sun is an average star.\"),\n",
    "    (\"What is the moon?\", \"The moon orbits the Earth.\"),\n",
    "    (\"Cooking tips\", \"I enjoy cooking and baking.\")\n",
    "]\n",
    "\n",
    "example_stats = example_evaluator.explore_and_calculate(example_data)\n",
    "print(\"Статистика по позициям релевантных ответов:\", example_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "IgRuY2XLxNVh"
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    ('What are some examples of toolkits that can be used for image format conversion and basic image manipulations?', 'umber of toolkits for converting from one image format to\\nanother, doing simple image manipulations such as size scaling, plus\\nthe above-mentioned 24 -> 8, color -> gray, gray -> b&w conversions.\\nHere are pointers to some of them:\\n\\n    xv by John Bra'),\n",
    "    ('What techniques are discussed in the context of quantizing 24-bit images down to 8 bits, and where can one find a relevant reference on this topic?', 'for\\nshading, chapter 19 for clipping, and branch out from there.\\n\\n\\n3) Quantizing 24 bit images down to 8 bits.\\n\\nFind a copy of \"Color Image Quantization for Frame Buffer Display\" by\\nPaul Heckbert, SIGGRAPH \\'82 Proceedings, page 297.  There are other\\n'),\n",
    "    ('How to FTP by email', ' 9) Converting between vector formats.\\n    10) How to get Pixar films.\\n    11) How do I draw a circle as a Bezier (or B-spline) curve?\\n    12) How to order standards documents.\\n    13) How to FTP by email.\\n    14) How to tell whether a point is withi'),\n",
    "    ('What steps should you take to obtain information about using the mail handler and software distribution?', ' exercises.  To receive information describing\\nhow you can use the mail handler, simply mail graphtext@cs.brown.edu\\nand put the word \"Help\" in the Subject line.  Use the Subject line\\n\"Software-Distribution\" to receive information specifically concern'),\n",
    "    ('How to join ACM/SIGGRAPH\\n', 'trace height fields\\n    24) How to find the area of a 3D polygon\\n    25) How to join ACM/SIGGRAPH\\n    26) Where can I find MRI and CT scan volume data?\\n    27) Specific references on spatial data structures including quadtrees\\n\\tand octrees\\n    28) Wh'),\n",
    "    ('How to get general information about the\\nmail server?', '/news.answers/pictures-faq/part1\\nsend usenet/news.answers/pictures-faq/part2\\n\\nSend a message containing \"help\" to get general information about the\\nmail server.\\n\\nAlso, you could check out the resources described in sections 7, 8, and\\n20 above for mor'),\n",
    "    ('How many tool the kit contains on image manipulation, digital halftoning?', 'rting pixels of arbitrary channels,\\n    components, and bit precisions while allowing compression and machine\\n    byte-order independence.  The kit contains more than 50 tools with\\n    extensive support of image manipulation, digital halftoning and f'),\n",
    "    ('A Fast Algorithm for Raster\\nRotation', 'implementation is\\nalso present in PBMPLUS.  Reference: \"A Fast Algorithm for Raster\\nRotation\", by Alan Paeth (awpaeth@watcgl.waterloo.edu) Graphics\\nInterface \\'86 (Vancouver).  An article on the IM toolkit appears in\\nthe same journal.  An updated vers'),\n",
    "    ('What are some examples of formats that can be converted or rendered by commercial PostScript clones for PCs?', \" to Sun raster format, or HPGL to\\nX11 bitmap.  For example, some of the commercial PostScript clones for\\nPC's allow you to render to a disk file as well as a printer.  Also,\\nthe PostScript interpreters in the NeXT box and in Sun's X11/NeWs can\\nbe use\"),\n",
    "    ('Why is assembly language used for over 100 functions in the graphical interface?', \"short or floating point arithmetic to maintain the precision\\n  and accuracy of the pixel format. Over 100 functions are hand-coded in\\n  assembly language for maximum speed on the Intel hardware.  The entire\\n  graphical interface is also written in as\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1hq4jqRAykA4",
    "outputId": "2131ccd0-7d9a-4e94-a6c4-6e515d2de691"
   },
   "outputs": [],
   "source": [
    "#Нужно написать эксперимент для оценки полученной коллекции\n",
    "collector = ChromaCollector(splitter, embedder)\n",
    "evaluator = CollectorEvaluator(collector, n_top=n_top)\n",
    "\n",
    "stats = evaluator.explore_and_calculate(data)\n",
    "print(\"Статистика по позициям релевантных ответов:\", stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "vnP32QsGMENI"
   },
   "outputs": [],
   "source": [
    "def generate(model_path, prompts, n_ctx=2000, top_k=30, top_p=0.9, temperature=0.2, repeat_penalty=1.1):\n",
    "  #Реализовать генерацию текста с помощью LLM модели\n",
    "  llm = Llama(model_path=model_path, n_ctx=n_ctx)\n",
    "\n",
    "  if isinstance(prompts, str):\n",
    "    prompts = [prompts]\n",
    "\n",
    "  responses = []\n",
    "\n",
    "  for prompt in prompts:\n",
    "    response = llm(prompt,\n",
    "                   top_k=top_k, top_p=top_p, temperature=temperature, \n",
    "                  #  repetition_penalty=repeat_penalty\n",
    "                   )\n",
    "    responses.append(response)\n",
    "\n",
    "  return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "8Dij2fi3MQh_"
   },
   "outputs": [],
   "source": [
    "class QuestionAndAnswers:\n",
    "    # Класс для представления вопросов и ответов\n",
    "    def __init__(self, question, correct_answer, generated_answer=None, prompt=None):\n",
    "        self.question = question\n",
    "        self.correct_answer = correct_answer\n",
    "        self.generated_answer = generated_answer\n",
    "        self.prompt = prompt\n",
    "\n",
    "    def __repr__(self):\n",
    "      return f\"Q: {self.question}\\nCorrect: {self.correct_answer}\\nGenerated: {self.generated_answer}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "JYgZ8Lr3MSZy"
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    # Класс для представления набора данных, содержащего вопросы и ответы.\n",
    "    def __init__(self, qa_list):\n",
    "      self.qa_list = qa_list\n",
    "\n",
    "def get_prompt(question, context):\n",
    "  return f'Answear the question: \"{question}\", using context: {context}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaGghTdGMX0C"
   },
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "e93b3899edc041ac8f7a8039d9e8fa52",
      "e7750855102c428e8d86079f10759d4d",
      "fe6cd592a4cb44299974814803d64dca",
      "f59614bafd17423eb0f28b0cf0404b50",
      "2b99c29b7c4049a0bb911b2024f4d9aa",
      "87a7758349104798b8eabaf4036b6916",
      "5b56b69baff44d24bc9b80f30ec5f245",
      "36ed2223fae948abbeebbbc6ff04ac75",
      "e013a4bc5377482489efae4adbbc1ea7",
      "49bf9f0bf07b4b9f820913d30a092cae",
      "f5dc20348ea340bdb636342351ae5d4e",
      "f4234ab97f4a4d94a76940170b4c0386",
      "941962a50b6b4cf19f0962e7c1d3f748",
      "f181fe130cb7439ca599c999333457d1",
      "347f07adeea34cdda852df42b897f0ba",
      "7981a4114e824bcd85d896fe2a261721",
      "754bf2b59aa94eb9840fbd655cfd5820",
      "fc55fd2dd6dd4915b30029ff1bce0a06",
      "085e9c2a2c434c2fab31c2badd6b376a",
      "3dc563a7806448bb89b40592d8f02ab4",
      "45dd02511b76415b82ba3485cca6bcfc",
      "18ad54a26ec5426ba16b2ad98945327f"
     ]
    },
    "id": "tBHRRUW5MZts",
    "outputId": "f77c10a5-bdc0-4c62-a0ed-a3fad44e4c85"
   },
   "outputs": [],
   "source": [
    "#Нужно написать эксперимент для генерации текста (ответа на вопрос) с помощью функции generate\n",
    "model_file=\"../assets/models/mistral-7b-openorca.Q4_K_M.gguf\" \n",
    "\n",
    "example_dataset = Dataset([\n",
    "    QuestionAndAnswers(\n",
    "        question='What is sun?',\n",
    "        correct_answer='The sun is an average star.'),\n",
    "])\n",
    "\n",
    "for qa in example_dataset.qa_list:\n",
    "  context = example_collector.get([qa.question], n_results=1)\n",
    "  qa.prompt = get_prompt(qa.question, context)\n",
    "\n",
    "  qa.generated_answer = generate(model_file, [qa.prompt])\n",
    "  print(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa.generated_answer[0]['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Нужно написать эксперимент для генерации текста (ответа на вопрос) с помощью функции generate\n",
    "model_file=\"../assets/models/mistral-7b-openorca.Q4_K_M.gguf\" \n",
    "\n",
    "dataset = Dataset([\n",
    "    QuestionAndAnswers(\n",
    "        question='How does Tom Van Flandern view the concept of \"dark matter\" and other unobservable phenomena in physics?',\n",
    "        correct_answer='Tom Van Flandern is skeptical of \"dark matter\" and other unobservable, purely theoretical constructs in physics, such as quarks and black holes. He questions whether their existence can be inferred solely from theory, suggesting that existence should be tied to observability.'\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question='What is the main point of disagreement between Tom Van Flandern and Bruce Scott on the concept of existence in physics?',\n",
    "        correct_answer='The main disagreement is that Bruce Scott argues \"existence\" should be synonymous with \"observable\" in physics, while Van Flandern challenges this view, particularly when considering phenomena like curvature, which he argues cannot exist without something \"non-curved\" to compare it to.'\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question='According to Nikola Tesla, why does he believe that space cannot be curved?',\n",
    "        correct_answer='Nikola Tesla argues that space cannot be curved because it has no properties on its own. He believes properties only apply to matter within space, and saying that large bodies curve space implies \"something can act upon nothing,\" a view he does not support.'\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question='What is the escape velocity equation in a circular orbit, and how does it relate to circular orbital velocity?',\n",
    "        correct_answer=' The escape velocity Vesc in a circular orbit is given by the equation Vesc = sqrt(2 * M * G / r) = sqrt(2) * Vс  is the circular orbital velocity. This means the escape velocity is approximately 1.41 times the circular orbital velocity.'\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question='What is the formula for calculating the Schwarzschild radius of a black hole, and what constants does it involve?',\n",
    "        correct_answer=\"The Schwarzschild radius of a black hole is calculated using the formula 2GM/c^2, where G is Newton's gravitational constant, M is the mass of the black hole, and c is the speed of light.\"\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question='Where are the Saturn V blueprints kept, and what is the main challenge in recreating the rocket?',\n",
    "        correct_answer='The Saturn V blueprints are kept at the Marshall Space Flight Center on microfilm. The main challenge in recreating the rocket is not finding the drawings, but sourcing 1960s-era hardware, such as guidance components, and the fact that launch facilities have been modified for the Space Shuttle.'\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question=\"Why isn't data from space missions immediately available to the public after collection?\",\n",
    "        correct_answer=\"NASA allows mission investigators exclusive access to data for one year after it's collected, giving them a chance to analyze and publish their results without competition. However, NASA often releases sample photos to the public early in a mission.\"\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question=\"What is the estimated environmental impact of the Space Shuttle's Solid Rocket Boosters on the ozone layer?\",\n",
    "        correct_answer=\"The impact of the Space Shuttle's Solid Rocket Boosters on the ozone layer is minimal, contributing less than 0.25% of total stratospheric chlorine sources. The effect on global ozone levels is estimated to be a decrease of only 0.0065%.\"\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question='What risks are associated with nuclear (RTG) power sources on space probes, and what evidence exists about their safety?',\n",
    "        correct_answer='Studies suggest that risks from nuclear RTG power sources on space probes are very low, even in worst-case scenarios, such as launch failures or reentry. For example, in 1968, two RTGs were recovered intact after a satellite failure, and in 1970, the Apollo 13 RTG fell into the ocean and remains safely contained.'\n",
    "        ),\n",
    "        QuestionAndAnswers(\n",
    "        question=\"Why can't the Space Shuttle be used for missions beyond low Earth orbit?\",\n",
    "        correct_answer='The Space Shuttle cannot be used for missions beyond low Earth orbit because it lacks sufficient fuel and is not designed for such missions. Its wings and other structural features are only useful near Earth, making it inefficient and costly for higher orbits.'\n",
    "        ),\n",
    "])\n",
    "\n",
    "for qa in dataset.qa_list:\n",
    "  context = collector.get([qa.question], n_results=1)\n",
    "  qa.prompt = get_prompt(qa.question, context)\n",
    "\n",
    "  qa.generated_answer = generate(model_file, [qa.prompt])\n",
    "  print(qa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.qa_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1BChqg7McMG"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6x44JDLMees"
   },
   "outputs": [],
   "source": [
    "import bert_score\n",
    "from typing import List\n",
    "\n",
    "class BERTScoreEvaluator:\n",
    "    # Класс для оценки качества сгенерированных ответов с использованием метрики BERTScore.\n",
    "    def __init__(self, model_type='distilbert-base-uncased'):\n",
    "        self.model_type = model_type\n",
    "    \n",
    "    def evaluate(self, reference: str, generated: str):\n",
    "        P, R, F1 = bert_score.score([generated], [reference], model_type=self.model_type)\n",
    "        return {\n",
    "            'precision': P.item(),\n",
    "            'recall': R.item(),\n",
    "            'f1': F1.item()\n",
    "        }\n",
    "\n",
    "    def evaluate_dataset(self, dataset: Dataset):\n",
    "        references = [qa.correct_answer for qa in dataset.qa_list]\n",
    "        generated_answers = [qa.generated_answer[0]['choices'][0]['text'] for qa in dataset.qa_list]\n",
    "\n",
    "        print(references)\n",
    "        print(generated_answers)\n",
    "\n",
    "        P, R, F1 = bert_score.score(generated_answers, references, model_type=self.model_type)\n",
    "        return {\n",
    "            'precision_mean': P.mean().item(),\n",
    "            'recall_mean': R.mean().item(),\n",
    "            'f1_mean': F1.mean().item()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKy4eQt6MkNW"
   },
   "outputs": [],
   "source": [
    "#Нужно написать эксперимент для оценки сгенерированых ответов\n",
    "bertScoreEvaluator = BERTScoreEvaluator()\n",
    "\n",
    "bert_result = bertScoreEvaluator.evaluate_dataset(dataset)\n",
    "print(bert_result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "085e9c2a2c434c2fab31c2badd6b376a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18ad54a26ec5426ba16b2ad98945327f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b99c29b7c4049a0bb911b2024f4d9aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "347f07adeea34cdda852df42b897f0ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45dd02511b76415b82ba3485cca6bcfc",
      "placeholder": "​",
      "style": "IPY_MODEL_18ad54a26ec5426ba16b2ad98945327f",
      "value": " 1/1 [00:00&lt;00:00, 52.74it/s]"
     }
    },
    "36ed2223fae948abbeebbbc6ff04ac75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3dc563a7806448bb89b40592d8f02ab4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "45dd02511b76415b82ba3485cca6bcfc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49bf9f0bf07b4b9f820913d30a092cae": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b56b69baff44d24bc9b80f30ec5f245": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "754bf2b59aa94eb9840fbd655cfd5820": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7981a4114e824bcd85d896fe2a261721": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87a7758349104798b8eabaf4036b6916": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "941962a50b6b4cf19f0962e7c1d3f748": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_754bf2b59aa94eb9840fbd655cfd5820",
      "placeholder": "​",
      "style": "IPY_MODEL_fc55fd2dd6dd4915b30029ff1bce0a06",
      "value": "Fetching 1 files: 100%"
     }
    },
    "e013a4bc5377482489efae4adbbc1ea7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e7750855102c428e8d86079f10759d4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87a7758349104798b8eabaf4036b6916",
      "placeholder": "​",
      "style": "IPY_MODEL_5b56b69baff44d24bc9b80f30ec5f245",
      "value": "Fetching 1 files: 100%"
     }
    },
    "e93b3899edc041ac8f7a8039d9e8fa52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e7750855102c428e8d86079f10759d4d",
       "IPY_MODEL_fe6cd592a4cb44299974814803d64dca",
       "IPY_MODEL_f59614bafd17423eb0f28b0cf0404b50"
      ],
      "layout": "IPY_MODEL_2b99c29b7c4049a0bb911b2024f4d9aa"
     }
    },
    "f181fe130cb7439ca599c999333457d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_085e9c2a2c434c2fab31c2badd6b376a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3dc563a7806448bb89b40592d8f02ab4",
      "value": 1
     }
    },
    "f4234ab97f4a4d94a76940170b4c0386": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_941962a50b6b4cf19f0962e7c1d3f748",
       "IPY_MODEL_f181fe130cb7439ca599c999333457d1",
       "IPY_MODEL_347f07adeea34cdda852df42b897f0ba"
      ],
      "layout": "IPY_MODEL_7981a4114e824bcd85d896fe2a261721"
     }
    },
    "f59614bafd17423eb0f28b0cf0404b50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49bf9f0bf07b4b9f820913d30a092cae",
      "placeholder": "​",
      "style": "IPY_MODEL_f5dc20348ea340bdb636342351ae5d4e",
      "value": " 1/1 [00:00&lt;00:00, 49.66it/s]"
     }
    },
    "f5dc20348ea340bdb636342351ae5d4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc55fd2dd6dd4915b30029ff1bce0a06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe6cd592a4cb44299974814803d64dca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36ed2223fae948abbeebbbc6ff04ac75",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e013a4bc5377482489efae4adbbc1ea7",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
