{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_file = \"../../nechkasova-tokenizer/assets/annotated-corpus/train/alt.atheism/49960.tsv\"\n",
    "dataset_path = \"../../nechkasova-tokenizer/assets/annotated-corpus/train/alt.atheism/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def read_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    return lines\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", '', text)\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path):\n",
    "    lines = read_data(file_path)\n",
    "    stems = []\n",
    "\n",
    "    for line in lines:\n",
    "        if line.strip():\n",
    "            try:\n",
    "                token, stem, lemma = line.strip().split('\\t')\n",
    "            except:\n",
    "                continue\n",
    "            cleaned_stems = clean_text(stem)\n",
    "            if cleaned_stems and cleaned_stems not in stop_words:\n",
    "                stems.append(cleaned_stems)\n",
    "    \n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def process_directory(directory_path):\n",
    "    all_stems = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            # print(f\"Process file {file_path}\")\n",
    "            stems = process_file(file_path)\n",
    "            all_stems.append(stems)\n",
    "\n",
    "    return all_stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stems = process_directory(dataset_path)\n",
    "all_stems = [stem_element for stem in stems for stem_element in stem]\n",
    "print(len(all_stems))\n",
    "stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write test on it\n",
    "def generate_bigrams(tokens):\n",
    "    bigrams = []\n",
    "    \n",
    "    for token_group in tokens:\n",
    "        for i in range(len(token_group) - 1):\n",
    "            bigram = (token_group[i], token_group[i + 1])\n",
    "            bigrams.append(bigram)\n",
    "    \n",
    "    return bigrams\n",
    "\n",
    "# Write test on it\n",
    "def generate_trigrams(tokens):\n",
    "    trigrams = []\n",
    "    \n",
    "    for token_group in tokens:\n",
    "        for i in range(len(token_group) - 2):\n",
    "            trigram = (token_group[i], token_group[i + 1], token_group[i + 2])\n",
    "            trigrams.append(trigram)\n",
    "    \n",
    "    return trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = generate_trigrams(stems)\n",
    "bigrams = generate_bigrams(stems)\n",
    "# M - N + 1\n",
    "print(len(all_stems) - 2 + 1, len(bigrams))\n",
    "print(len(all_stems) - 3 + 1, len(trigrams))\n",
    "trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write test on it\n",
    "def count_bigram_entry(bigram, bigrams):\n",
    "    O_11 = 0\n",
    "    O_12 = 0\n",
    "    O_21 = 0\n",
    "    O_22 = 0\n",
    "    for bigram_entity in bigrams:\n",
    "        try:\n",
    "            index_to_remove = bigram.index(bigram_entity[0])\n",
    "            if bigram_entity[1] == bigram[1 - index_to_remove]:\n",
    "                O_11 += 1\n",
    "            else:\n",
    "                O_12 += 1\n",
    "        except ValueError:\n",
    "            try:\n",
    "                index_to_remove = bigram.index(bigram_entity[1])\n",
    "                O_21 += 1\n",
    "            except ValueError:\n",
    "                O_22 += 1\n",
    "    \n",
    "    return O_11, O_12, O_21, O_22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_list = {('foo', 'bar'),\n",
    "                ('foo', 'baz'),\n",
    "                ('qux', 'quux'),\n",
    "                ('quux', 'foo'),\n",
    "                ('corge', 'bar'),\n",
    "                ('bar', 'grault')}\n",
    "bigram = ('foo', 'bar')\n",
    "\n",
    "print(count_bigram_entry(bigram, bigram_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist\n",
    "            \n",
    "# Write test on it\n",
    "def count_token_freq(tokens):\n",
    "    tokens_freq = FreqDist(tokens)\n",
    "    return tokens_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write test on it\n",
    "def count_trigram_entry(trigram, trigrams):\n",
    "    O_111 = 0\n",
    "    O_121 = 0\n",
    "    O_211 = 0\n",
    "    O_221 = 0\n",
    "    \n",
    "    O_112 = 0\n",
    "    O_122 = 0\n",
    "    O_212 = 0\n",
    "    O_222 = 0\n",
    "    \n",
    "    for trigram_entity in trigrams:\n",
    "        try:\n",
    "            index_to_remove = trigram_entity.index(trigram[0])\n",
    "            rest_trigram_elements = trigram_entity[:index_to_remove] + trigram_entity[index_to_remove+1:]\n",
    "            try:\n",
    "                index_to_remove = rest_trigram_elements.index(trigram[1])\n",
    "                if trigram[2] == rest_trigram_elements[1 - index_to_remove]:\n",
    "                    O_111 += 1\n",
    "                else:\n",
    "                    O_121 += 1\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    index_to_remove = rest_trigram_elements.index(trigram[2])\n",
    "                    O_211 += 1\n",
    "                except ValueError:\n",
    "                    O_221 += 1\n",
    "        except ValueError:\n",
    "            try:\n",
    "                index_to_remove = trigram_entity.index(trigram[1])\n",
    "                rest_trigram_elements = trigram_entity[:index_to_remove] + trigram_entity[index_to_remove+1:]\n",
    "                try:\n",
    "                    index_to_remove = trigram_entity.index(trigram[2])\n",
    "                    O_112 += 1\n",
    "                except ValueError:\n",
    "                    O_122 += 1\n",
    "            except ValueError:\n",
    "                try:\n",
    "                    index_to_remove = trigram_entity.index(trigram[2])\n",
    "                    rest_trigram_elements = trigram_entity[:index_to_remove] + trigram_entity[index_to_remove+1:]\n",
    "                    O_212 += 1\n",
    "                except ValueError:\n",
    "                    O_222 += 1\n",
    "    return O_111, O_121, O_211, O_221, O_112, O_122, O_212, O_222\n",
    "\n",
    "def _contingency(n_iii, n_iix, n_ixi, n_ixx, n_xii, n_xix, n_xxi, n_xxx):\n",
    "    \"\"\"Calculates values of a trigram contingency table (or cube) from\n",
    "    marginal values.\n",
    "    >>> TrigramAssocMeasures._contingency(1, (1, 1, 1), (1, 73, 1), 2000)\n",
    "    (1, 0, 0, 0, 0, 72, 0, 1927)\n",
    "    \"\"\"\n",
    "    n_oii = n_xii - n_iii\n",
    "    n_ioi = n_ixi - n_iii\n",
    "    n_iio = n_iix - n_iii\n",
    "    n_ooi = n_xxi - n_iii - n_oii - n_ioi\n",
    "    n_oio = n_xix - n_iii - n_oii - n_iio\n",
    "    n_ioo = n_ixx - n_iii - n_ioi - n_iio\n",
    "    n_ooo = n_xxx - n_iii - n_oii - n_ioi - n_iio - n_ooi - n_oio - n_ioo\n",
    "\n",
    "    return (n_iii, n_oii, n_ioi, n_ooi, n_iio, n_oio, n_ioo, n_ooo)\n",
    "\n",
    "def count_trigram_entry_without_rearrangement(trigram, trigrams):\n",
    "    O_111 = 0\n",
    "    O_121 = 0\n",
    "    O_211 = 0\n",
    "    O_221 = 0\n",
    "    \n",
    "    O_112 = 0\n",
    "    O_122 = 0\n",
    "    O_212 = 0\n",
    "    O_222 = 0\n",
    "    \n",
    "    for trigram_entity in trigrams:\n",
    "        if trigram_entity[0] == trigram[0]:\n",
    "            if trigram_entity[1] == trigram[1]:\n",
    "                if trigram_entity[2] == trigram[2]:\n",
    "                    O_111 += 1\n",
    "                else:\n",
    "                    O_121 += 1\n",
    "            else:\n",
    "                if trigram_entity[2] == trigram[2]:\n",
    "                    O_211 += 1\n",
    "                else:\n",
    "                    O_221 += 1\n",
    "        else:\n",
    "            if trigram_entity[1] == trigram[1]:\n",
    "                if trigram_entity[2] == trigram[2]:\n",
    "                    O_112 += 1\n",
    "                else:\n",
    "                    O_122 += 1\n",
    "            else:\n",
    "                if trigram_entity[2] == trigram[2]:\n",
    "                    O_212 += 1\n",
    "                else:\n",
    "                    O_222 += 1\n",
    "                    \n",
    "    return O_111, O_121, O_211, O_221, O_112, O_122, O_212, O_222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write test on it\n",
    "\n",
    "tokens = ('summari', 'book', 'address', 'summer', 'book' 'magazines', 'address')\n",
    "trigram_list = [('summari', 'book', 'address'),\n",
    "                ('book', 'address', 'summer'),\n",
    "                ('summer', 'book', 'address'),\n",
    "                ('summer', 'book', 'magazines'),\n",
    "                ('book', 'magazines', 'address')]\n",
    "trigram = ('summer', 'book', 'address')\n",
    "token = 'address'\n",
    "\n",
    "print(count_trigram_entry(trigram, trigram_list))\n",
    "print(count_trigram_entry_without_rearrangement(trigram, trigram_list))\n",
    "print(count_token_freq(tokens)[token])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Write test on it\n",
    "def calculate_t_score_for_bigrams(bigram, bigrams, stems):\n",
    "    try:\n",
    "        total_tokens = len(all_stems)\n",
    "        count_bigram = count_token_freq(bigrams)[bigram]\n",
    "        \n",
    "        token_freq = count_token_freq(all_stems)\n",
    "        count_element_0 = token_freq[bigram[0]]\n",
    "        count_element_1 = token_freq[bigram[1]]\n",
    "        \n",
    "        t_score = (count_bigram - (count_element_0 * count_element_1 / total_tokens)) / math.sqrt(count_bigram)\n",
    "    except:\n",
    "        return 0\n",
    "    return t_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ('foo', 'bar', \n",
    "          'foo', 'baz', \n",
    "          'qux', 'quux', 'foo', \n",
    "          'corge', 'bar', 'grault')\n",
    "bigram_list = {('foo', 'bar'),\n",
    "                ('foo', 'baz'),\n",
    "                ('qux', 'quux'),\n",
    "                ('quux', 'foo'),\n",
    "                ('corge', 'bar'),\n",
    "                ('bar', 'grault')}\n",
    "bigram = ('foo', 'bar')\n",
    "\n",
    "calculate_t_score_for_bigrams(bigram, bigram_list, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write test on it\n",
    "def calculate_t_score_for_trigrams(trigram, trigram_list, tokens):\n",
    "    total_tokens = len(tokens)\n",
    "    count_trigram = count_token_freq(trigram_list)[trigram]\n",
    "    \n",
    "    if count_trigram == 0 or total_tokens == 0:\n",
    "        return None\n",
    "    \n",
    "    token_freq = count_token_freq(tokens)\n",
    "    count_element_0 = token_freq[trigram[0]]\n",
    "    count_element_1 = token_freq[trigram[1]]\n",
    "    count_element_2 = token_freq[trigram[2]]\n",
    "    \n",
    "    t_score = (count_trigram - (count_element_0 * count_element_1 * count_element_2 / total_tokens**2)) / math.pow(count_trigram, 1/3)\n",
    "    \n",
    "    return t_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ('summari', 'book', 'address', 'summer', 'book' 'magazines', 'address')\n",
    "trigram_list = [('summari', 'book', 'address'),\n",
    "                ('book', 'address', 'summer'),\n",
    "                ('address', 'summer', 'book'),\n",
    "                ('summer', 'book', 'magazines'),\n",
    "                ('book', 'magazines', 'address')]\n",
    "trigram = ('address', 'summer', 'book')\n",
    "\n",
    "calculate_t_score_for_trigrams(trigram, trigram_list, tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SMALL = 1e-20\n",
    "\n",
    "def calculate_for_OE(O, E):\n",
    "    if E == 0 or O == 0:\n",
    "        return 0\n",
    "    print(O, E)\n",
    "    return O * math.log(O / (E + _SMALL) + _SMALL)\n",
    "\n",
    "def calculate_log_likelihood_for_bigrams(bigram, bigrams, N):\n",
    "    O_11, O_12, O_21, O_22 = count_bigram_entry(bigram, bigrams)\n",
    "    R_1 = O_11 + O_12\n",
    "    R_2 = O_21 + O_22\n",
    "    C_1 = O_11 + O_21\n",
    "    C_2 = O_12 + O_22\n",
    "    \n",
    "    E_11 = R_1 * C_1 / N\n",
    "    E_12 = R_1 * C_2 / N\n",
    "    E_21 = R_2 * C_1 / N\n",
    "    E_22 = R_2 * C_2 / N\n",
    "\n",
    "    log_likelihood = 2 * (calculate_for_OE(O_11, E_11) + calculate_for_OE(O_12, E_12) + calculate_for_OE(O_21, E_21) + calculate_for_OE(O_22, E_22))\n",
    "    \n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_list = {('foo', 'bar'),\n",
    "                ('foo', 'baz'),\n",
    "                ('qux', 'quux'),\n",
    "                ('quux', 'foo'),\n",
    "                ('corge', 'bar'),\n",
    "                ('bar', 'grault')}\n",
    "bigram = ('foo', 'bar')\n",
    "N = 10\n",
    "\n",
    "calculate_log_likelihood_for_bigrams(bigram, bigram_list, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_likelihood_for_trigrams(trigram, trigrams, N):\n",
    "    O_111, O_121, O_211, O_221, O_112, O_122, O_212, O_222 = count_trigram_entry_without_rearrangement(trigram, trigrams)\n",
    "    print(O_111, O_121, O_211, O_221, O_112, O_122, O_212, O_222)\n",
    "    R_1 = O_111 + O_121 + O_112 + O_122\n",
    "    R_2 = O_211 + O_221 + O_212 + O_222\n",
    "    C_1 = O_111 + O_211 + O_112 + O_212\n",
    "    C_2 = O_121 + O_221 + O_122 + O_222\n",
    "    B_1 = O_111 + O_121 + O_211 + O_221\n",
    "    B_2 = O_112 + O_122 + O_212 + O_222\n",
    "    \n",
    "    E_111 = R_1 * C_1 * B_1 / N\n",
    "    E_121 = R_1 * C_2 * B_1 / N\n",
    "    E_211 = R_2 * C_1 * B_1 / N\n",
    "    E_221 = R_2 * C_2 * B_1 / N\n",
    "    \n",
    "    E_112 = R_1 * C_1 * B_2 / N\n",
    "    E_122 = R_1 * C_2 * B_2 / N\n",
    "    E_212 = R_2 * C_1 * B_2 / N\n",
    "    E_222 = R_2 * C_2 * B_2 / N\n",
    "\n",
    "    log_likelihood = 2 * (calculate_for_OE(O_111, E_111) + calculate_for_OE(O_121, E_121) + calculate_for_OE(O_211, E_211) + calculate_for_OE(O_221, E_221) + \n",
    "                          calculate_for_OE(O_112, E_112) + calculate_for_OE(O_122, E_122) + calculate_for_OE(O_212, E_212) + calculate_for_OE(O_222, E_222))\n",
    "    \n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ('summari', 'book', 'address', 'summer', 'book' 'magazines', 'address', 'summmer', \n",
    "          'hot', 'water', 'summer',\n",
    "          'address', 'line', 'water', 'sun', 'book')\n",
    "trigram_list = [('summari', 'book', 'address'),\n",
    "                ('book', 'address', 'summer'),\n",
    "                ('summer', 'book', 'address'),\n",
    "                ('summer', 'book', 'magazines'),\n",
    "                ('book', 'magazines', 'address'),\n",
    "                ('magazines', 'address', 'summer'),\n",
    "                ('hot', 'water', 'summer'),\n",
    "                ('address', 'line', 'water'),\n",
    "                ('line', 'water', 'sun'),\n",
    "                ('water', 'sun', 'book')]\n",
    "trigram = ('book', 'address', 'summer')\n",
    "N = len(tokens)\n",
    "\n",
    "calculate_log_likelihood_for_trigrams(trigram, trigram_list, len(trigram_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "text = nltk.Text(tokens)\n",
    "\n",
    "finder_thr = TrigramCollocationFinder.from_words(text)\n",
    "\n",
    "print(finder_thr.score_ngram(trigram_measures.likelihood_ratio, 'book', 'address', 'summer'))\n",
    "print(finder_thr.score_ngrams(trigram_measures.likelihood_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_map = {}\n",
    "\n",
    "for bigram in bigrams:\n",
    "    t_score = calculate_t_score_for_bigrams(bigram, bigrams, all_stems)\n",
    "    log_likelihood = calculate_log_likelihood_for_bigrams(bigram, bigrams, len(all_stems))\n",
    "    bigrams_map[bigram] = {'t_score': t_score, 'log_likelihood': log_likelihood}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_bigrams = sorted(bigrams_map.items(), key=lambda item: item[1]['t_score'], reverse=True)\n",
    "\n",
    "for bigram, metrics in sorted_bigrams:\n",
    "    print(f\"{bigram}: t_score={metrics['t_score']}, log_likelihood={metrics['log_likelihood']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_bigrams = sorted(bigrams_map.items(), key=lambda item: item[1]['log_likelihood'], reverse=True)\n",
    "\n",
    "for bigram, metrics in sorted_bigrams:\n",
    "    print(f\"{bigram}: t_score={metrics['t_score']}, log_likelihood={metrics['log_likelihood']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "text = nltk.Text(all_stems)\n",
    "\n",
    "finder_bi = BigramCollocationFinder.from_words(text)\n",
    "\n",
    "print('Results with nltk realization\\n')\n",
    "print(f'Bigrams by student_t:\\n{finder_bi.nbest(bigram_measures.student_t, 30)}\\n')\n",
    "print(f'Bigrams by log-likelihoog:\\n{finder_bi.nbest(bigram_measures.likelihood_ratio, 30)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_map = {}\n",
    "\n",
    "for trigram in trigrams:\n",
    "    t_score = calculate_t_score_for_trigrams(trigram, trigrams, all_stems)\n",
    "    log_likelihood = calculate_log_likelihood_for_trigrams(trigram, trigrams, len(all_stems))\n",
    "    trigrams_map[trigram] = {'t_score': t_score, 'log_likelihood': log_likelihood}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_trigrams = sorted(trigrams_map.items(), key=lambda item: item[1]['t_score'], reverse=True)\n",
    "\n",
    "for trigram, metrics in sorted_trigrams:\n",
    "    print(f\"{trigram}: t_score={metrics['t_score']}, log_likelihood={metrics['log_likelihood']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_trigrams = sorted(trigrams_map.items(), key=lambda item: item[1]['log_likelihood'], reverse=True)\n",
    "\n",
    "for trigram, metrics in sorted_trigrams:\n",
    "    print(f\"{trigram}: t_score={metrics['t_score']}, log_likelihood={metrics['log_likelihood']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "text = nltk.Text(all_stems)\n",
    "\n",
    "finder_thr = TrigramCollocationFinder.from_words(text)\n",
    "\n",
    "print('Results with nltk realization\\n')\n",
    "print(f'Trigrams by student_t:\\n{finder_thr.nbest(trigram_measures.student_t, 30)}\\n')\n",
    "print(f'Trigrams by log-likelihoog:\\n{finder_thr.nbest(trigram_measures.likelihood_ratio, 30)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
